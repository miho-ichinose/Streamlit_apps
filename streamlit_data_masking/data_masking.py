# Streamlit ãƒ‡ãƒ¼ã‚¿ãƒã‚¹ã‚­ãƒ³ã‚°å°‚ç”¨ãƒ„ãƒ¼ãƒ« (Masker)
# ------------------------------------------------------------
# ä½¿ã„æ–¹:
# 1) pip install streamlit pandas openpyxl xlsxwriter
# 2) ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ data_masking.py ã¨ã—ã¦ä¿å­˜
# 3) streamlit run data_masking.py
#
# æ©Ÿèƒ½(ãƒã‚¹ã‚­ãƒ³ã‚°ç‰¹åŒ–):
# - å…¥åŠ›: CSV/TSV/Excel èª­ã¿è¾¼ã¿ï¼ˆUTF-8-SIG/UTF-8/CP932ã®é †ã§è‡ªå‹•åˆ¤å®šï¼‰
# - åˆ—ã”ã¨ã«ãƒã‚¹ã‚­ãƒ³ã‚°æ–¹å¼ã‚’é¸æŠ
#   * å…¨ãƒã‚¹ã‚¯(****)
#   * å…ˆé ­N/æœ«å°¾Mä»¥å¤–ãƒã‚¹ã‚¯ï¼ˆä¸­å¤®ã‚’*ï¼‰
#   * SHA256ãƒãƒƒã‚·ãƒ¥ï¼ˆä»»æ„ã‚½ãƒ«ãƒˆï¼‰
#   * ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ï¼ˆå®‰å®šãƒãƒƒãƒ”ãƒ³ã‚°ï¼‰/ ãƒãƒƒãƒ—ã®JSONå…¥å‡ºåŠ›
#   * æ­£è¦è¡¨ç¾ã§ä¸€è‡´éƒ¨åˆ†ã®ã¿ãƒã‚¹ã‚¯
#   * ãƒ—ãƒªã‚»ãƒƒãƒˆï¼ˆEmail/Phone/CreditCardï¼‰
# - å‡ºåŠ›: CSV/TSV/Excelã€ãƒˆãƒ¼ã‚¯ãƒ³ãƒãƒƒãƒ—(JSON)ã€å®Ÿè¡Œãƒãƒªã‚·ãƒ¼(JSON)
# ------------------------------------------------------------

import io
import re
import json
import hashlib
import pandas as pd
import streamlit as st
import os
import time

st.set_page_config(page_title="ãƒ‡ãƒ¼ã‚¿ãƒã‚¹ã‚­ãƒ³ã‚°å°‚ç”¨ãƒ„ãƒ¼ãƒ«", layout="wide")
st.title("ğŸ”’ ãƒ‡ãƒ¼ã‚¿ãƒã‚¹ã‚­ãƒ³ã‚°å°‚ç”¨ãƒ„ãƒ¼ãƒ«")

# -------------------------------
# Utility
# -------------------------------




def read_table_from_path(path: str, sheet_name=None, header=0) -> pd.DataFrame:
    lower = path.lower()
    # Excel
    if lower.endswith((".xlsx", ".xls")):
        return pd.read_excel(path, sheet_name=sheet_name, header=header)
    # Gzipåœ§ç¸®CSV/TSV
    if lower.endswith(".gz"):
        sep = "	" if lower.endswith(".tsv.gz") or ".tsv" in lower else ","
        return pd.read_csv(path, compression="gzip", sep=sep, header=header)
    # é€šå¸¸CSV/TSV
    sep = "	" if lower.endswith(".tsv") else ","
    try:
        return pd.read_csv(path, sep=sep, header=header)
    except Exception:
        return pd.read_csv(path, sep=sep, engine="python", header=header)


def read_preview_from_path(path: str, sheet_name=None, header=0, nrows: int = 200) -> pd.DataFrame:
    """å…ˆé ­ nrows è¡Œã ã‘ã‚’é«˜é€Ÿã«èª­ã‚€è»½é‡ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã€‚Excelã¯ pandas ã®å¯¾å¿œçŠ¶æ³ã«ã‚ˆã‚Šãƒ•ãƒ«èª­ã¿è¾¼ã¿ + head ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚"""
    lower = path.lower()
    try:
        if lower.endswith((".xlsx", ".xls")):
            try:
                return pd.read_excel(path, sheet_name=sheet_name, header=header, nrows=nrows)
            except TypeError:
                df_full = pd.read_excel(path, sheet_name=sheet_name, header=header)
                return df_full.head(nrows)
        if lower.endswith(".gz"):
            sep = "	" if lower.endswith(".tsv.gz") or ".tsv" in lower else ","
            return pd.read_csv(path, compression="gzip", sep=sep, header=header, nrows=nrows)
        sep = "	" if lower.endswith(".tsv") else ","
        return pd.read_csv(path, sep=sep, header=header, nrows=nrows)
    except Exception:
        df = read_table_from_path(path, sheet_name=sheet_name, header=header)
        return df.head(nrows)

def sha256_hash(x: str, salt: str = "") -> str:
    return hashlib.sha256((salt + x).encode()).hexdigest()


# ãƒˆãƒ¼ã‚¯ãƒ³åŒ–: ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§å®‰å®šã€‚æ—¢å­˜ãƒãƒƒãƒ—ã‚’é©ç”¨ã—ã€æœªç™»éŒ²ã®ã¿æ–°è¦æ¡ç•ªã€‚
if "token_map" not in st.session_state:
    st.session_state.token_map = {}


def tokenize_series(series: pd.Series, prefix: str = "TKN_") -> pd.Series:
    tm = st.session_state.token_map
    out = []
    counter = len(tm) + 1
    for v in series.astype(str).fillna(""):
        if v == "":
            out.append("")
            continue
        if v not in tm:
            tm[v] = f"{prefix}{counter:07d}"
            counter += 1
        out.append(tm[v])
    return pd.Series(out, index=series.index)


def mask_full(s: pd.Series) -> pd.Series:
    return s.astype(str).apply(lambda x: "****" if x else "")


def mask_keep_head_tail(s: pd.Series, head: int = 0, tail: int = 0) -> pd.Series:
    s = s.astype(str).fillna("")
    return s.apply(lambda x: (x[:head] + ("*" * max(0, len(x) - head - tail)) + x[-tail:]) if x else "")


def mask_regex_sub(s: pd.Series, pattern: str, repl_char: str = "*") -> pd.Series:
    try:
        reg = re.compile(pattern)
    except re.error as e:
        st.error(f"æ­£è¦è¡¨ç¾ã‚¨ãƒ©ãƒ¼: {e}")
        return s
    return s.astype(str).apply(lambda x: reg.sub(lambda m: repl_char * len(m.group(0)), x) if x else "")

# ---- è¿½åŠ : ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ----

def _sep_from_path(path: str) -> str:
    lower = path.lower()
    return "	" if lower.endswith(".tsv") or lower.endswith(".tsv.gz") else ","


def _apply_masking(chunk: pd.DataFrame, cols: list, method: str, head_n: int, tail_n: int, salt: str, regex_pat: str, preset: str) -> pd.DataFrame:
    if not cols:
        return chunk
    for c in cols:
        if c not in chunk.columns:
            continue
        s = chunk[c].astype(str).fillna("")
        if method == "å…¨ãƒã‚¹ã‚¯(****)":
            chunk[c] = s.apply(lambda x: "****" if x else "")
        elif method == "å…ˆé ­N/æœ«å°¾Mä»¥å¤–ãƒã‚¹ã‚¯":
            chunk[c] = s.apply(lambda x: (x[:head_n] + ("*" * max(0, len(x) - head_n - tail_n)) + x[-tail_n:]) if x else "")
        elif method == "SHA256ãƒãƒƒã‚·ãƒ¥":
            chunk[c] = s.apply(lambda x: sha256_hash(x, salt=salt) if x else "")
        elif method == "ãƒˆãƒ¼ã‚¯ãƒ³åŒ–(ä¸€æ„ãƒãƒƒãƒ”ãƒ³ã‚°)":
            # æ—¢å­˜ã®token_mapã‚’ä½¿ã£ã¦å®‰å®šãƒãƒƒãƒ”ãƒ³ã‚°
            tm = st.session_state.token_map
            out = []
            counter = len(tm) + 1
            for v in s:
                if v == "":
                    out.append("")
                    continue
                if v not in tm:
                    tm[v] = f"TKN_{counter:07d}"
                    counter += 1
                out.append(tm[v])
            chunk[c] = pd.Series(out, index=s.index)
        elif method == "æ­£è¦è¡¨ç¾ã§ä¸€è‡´éƒ¨åˆ†ã®ã¿ãƒã‚¹ã‚¯":
            if regex_pat:
                try:
                    reg = re.compile(regex_pat)
                    chunk[c] = s.apply(lambda x: reg.sub(lambda m: "*" * len(m.group(0)), x) if x else "")
                except re.error as e:
                    st.error(f"æ­£è¦è¡¨ç¾ã‚¨ãƒ©ãƒ¼: {e}")
            else:
                st.error("æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        elif method == "ãƒ—ãƒªã‚»ãƒƒãƒˆ: Email/Phone/CreditCard":
            fn = PRESETS[preset]["func"]
            chunk[c] = s.apply(lambda x: fn(x) if x else "")
    return chunk


def stream_mask_save(path: str, header_has_names: bool, cols: list, method: str, head_n: int, tail_n: int, salt: str, regex_pat: str, preset: str, chunksize: int, out_dir: str = None, gzip_save: bool = False) -> str:
    """å¤§å®¹é‡å‘ã‘: ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã§ãƒã‚¹ã‚¯ã—ãªãŒã‚‰CSV/TSVã«è¿½è¨˜ä¿å­˜ã™ã‚‹ã€‚æˆ»ã‚Šå€¤ã¯å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€‚"""
    sep = _sep_from_path(path)
    header = 0 if header_has_names else None

    base = os.path.basename(path)
    lower = base.lower()
    for suf in [".csv.gz",".tsv.gz",".xlsx",".xls",".csv",".tsv"]:
        if lower.endswith(suf):
            base = base[: -len(suf)]
            break
    ext = ".tsv" if sep == "	" else ".csv"
    out_name = f"{base}_maked{ext}"
    if gzip_save and ext == ".csv":
        out_name += ".gz"
    out_dir = out_dir or os.path.dirname(path)
    out_path = os.path.join(out_dir, out_name)

    # Excelã¯ãƒãƒ£ãƒ³ã‚¯æœªå¯¾å¿œã®ãŸã‚ãƒ•ãƒ«ãƒ­ãƒ¼ãƒ‰è­¦å‘Š
    if path.lower().endswith((".xlsx",".xls")):
        st.warning("Excelã¯ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åˆ†å‰²èª­ã¿è¾¼ã¿ã«å¯¾å¿œã—ã¦ã„ãªã„ãŸã‚ã€ãƒ•ãƒ«ãƒ­ãƒ¼ãƒ‰ã§å‡¦ç†ã—ã¾ã™ã€‚æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆã¯CSVã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚")
        df_full = read_table_from_path(path, header=header)
        df_full = _apply_masking(df_full, cols, method, head_n, tail_n, salt, regex_pat, preset)
        df_full.to_csv(out_path, index=False, sep=sep, encoding="utf-8-sig")
        return out_path

    # CSV/TSV: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
    write_header = True
    processed = 0
    start = time.time()
    progress = st.progress(0, text="å‡¦ç†é–‹å§‹â€¦")
    status = st.empty()

    # åœ§ç¸®è¨­å®š
    compression = "gzip" if gzip_save and ext == ".csv" else None

    for chunk in pd.read_csv(path, sep=sep, header=header, chunksize=chunksize, dtype=str, keep_default_na=False, na_filter=False):
        chunk = _apply_masking(chunk, cols, method, head_n, tail_n, salt, regex_pat, preset)
        chunk.to_csv(out_path, mode="a", index=False, sep=sep, header=write_header, encoding="utf-8-sig", compression=compression)
        write_header = False
        processed += len(chunk)
        elapsed = time.time() - start
        status.text(f"å‡¦ç†è¡Œæ•°: {processed:,}  | çµŒé: {elapsed:.1f}s  | å‡ºåŠ›: {os.path.basename(out_path)}")
        # é€²æ—ã¯ä¸ç¢ºå®šãªã®ã§ç–‘ä¼¼çš„ã«ã‚†ã£ãã‚Šä¸Šã’ã‚‹
        p = min(100, int((elapsed % 10) * 10))
        progress.progress(p, text="å‡¦ç†ä¸­â€¦")

    progress.progress(100, text="å®Œäº†")
    return out_path


# ãƒ—ãƒªã‚»ãƒƒãƒˆé–¢æ•°
PRESETS = {
    "Email(ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’ãƒã‚¹ã‚¯)": {
        "func": lambda x: re.sub(r"([A-Za-z0-9._%+-]+)@([A-Za-z0-9.-]+)", lambda m: m.group(1) + "@" + "*" * len(m.group(2)), x)
    },
    "Phone(ä¸­é–“ã‚’ãƒã‚¹ã‚¯)": {
        "func": lambda x: re.sub(r"(\d{2,4})([- ]?)(\d{2,4})([- ]?)(\d{3,4})", lambda m: m.group(1) + m.group(2) + "*" * len(m.group(3)) + m.group(4) + m.group(5), x)
    },
    "CreditCard(æœ€å¾Œ4æ¡æ®‹ã—)": {
        "func": lambda x: (lambda digits: ("*" * max(0, len(digits) - 4)) + digits[-4:])(re.sub(r"[^\d]", "", x))
    },
}

# -------------------------------
# Input
# -------------------------------
# èª­ã¿è¾¼ã¿ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰
header_has_names = st.sidebar.checkbox("ãƒ˜ãƒƒãƒ€è¡Œã‚ã‚Šï¼ˆ1è¡Œç›®ã¯åˆ—åï¼‰", value=True)
light_nrows = st.sidebar.number_input("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡Œæ•°ï¼ˆnrowsï¼‰", min_value=5, max_value=5000, value=200, step=5)
left, right = st.columns([2, 1])
with left:
    # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æŒ‡å®šã®ã¿ï¼ˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã¯å‰Šé™¤ï¼‰
    path = st.text_input("ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å…¥åŠ› (CSV/TSV/Excel/.gz å¯¾å¿œ)")
    sheet = None
    if path and path.lower().endswith((".xlsx", ".xls")):
        sheet = st.text_input("Excelã®ã‚·ãƒ¼ãƒˆåï¼ˆæœªæŒ‡å®šãªã‚‰å…ˆé ­ï¼‰", value="") or None

    if not path:
        st.info("ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ä¾‹: C:/data/bigfile.csv.gz")
        st.stop()

    # å­˜åœ¨ç¢ºèª & ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºè¡¨ç¤º
    if not os.path.exists(path):
        st.error("æŒ‡å®šã®ãƒ‘ã‚¹ã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å­˜åœ¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    try:
        size_mb = os.path.getsize(path) / (1024 * 1024)
        st.caption(f"ğŸ“„ {os.path.basename(path)} | ã‚µã‚¤ã‚º: {size_mb:.2f} MB")
    except Exception:
        pass

    # èª­ã¿è¾¼ã¿ï¼ˆè»½é‡ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼å°‚ç”¨ï¼‰
    t0 = time.time()
    try:
        with st.spinner("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’èª­ã¿è¾¼ã¿ä¸­â€¦"):
            df = read_preview_from_path(path, sheet_name=sheet, header=0 if header_has_names else None, nrows=int(light_nrows))
    except Exception as e:
        st.exception(e)
        st.stop()
    dt = time.time() - t0
    st.success(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼èª­ã¿è¾¼ã¿: {len(df)}è¡Œ Ã— {df.shape[1]}åˆ— | æ‰€è¦ {dt:.2f} ç§’ï¼ˆå…ˆé ­ã®ã¿ï¼‰")

    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºè¡Œæ•°ï¼ˆèª­ã¿è¾¼ã‚“ã ç¯„å›²å†…ã§èª¿æ•´ï¼‰
    max_rows = max(5, min(200, len(df)))
    n_preview = st.slider("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºè¡Œæ•°", 5, max_rows, min(50, max_rows), 5)
    st.dataframe(df.head(n_preview), use_container_width=True)

with right:
    st.subheader("åˆ—æƒ…å ±")
    info = pd.DataFrame({
        "column": df.columns,
        "dtype": [str(t) for t in df.dtypes],
        "nulls": df.isna().sum().values,
        "unique": [df[c].nunique(dropna=True) for c in df.columns],
    })
    st.dataframe(info, use_container_width=True, height=400)

# -------------------------------
# Sidebar: Masking Config
# -------------------------------
st.sidebar.header("ğŸ›¡ï¸ ãƒã‚¹ã‚­ãƒ³ã‚°è¨­å®š")
cols = st.sidebar.multiselect("å¯¾è±¡åˆ—(è¤‡æ•°å¯)", options=list(df.columns))
method = st.sidebar.selectbox(
    "æ–¹å¼",
    [
        "å…¨ãƒã‚¹ã‚¯(****)",
        "å…ˆé ­N/æœ«å°¾Mä»¥å¤–ãƒã‚¹ã‚¯",
        "SHA256ãƒãƒƒã‚·ãƒ¥",
        "ãƒˆãƒ¼ã‚¯ãƒ³åŒ–(ä¸€æ„ãƒãƒƒãƒ”ãƒ³ã‚°)",
        "æ­£è¦è¡¨ç¾ã§ä¸€è‡´éƒ¨åˆ†ã®ã¿ãƒã‚¹ã‚¯",
        "ãƒ—ãƒªã‚»ãƒƒãƒˆ: Email/Phone/CreditCard",
    ],
)

head_n = st.sidebar.number_input("å…ˆé ­ã«æ®‹ã™æ–‡å­—æ•°", 0, 100, 2)
_tail_n = st.sidebar.number_input("æœ«å°¾ã«æ®‹ã™æ–‡å­—æ•°", 0, 100, 2)
salt = st.sidebar.text_input("ãƒãƒƒã‚·ãƒ¥ç”¨ã‚½ãƒ«ãƒˆ(ä»»æ„)")
regex_pat = st.sidebar.text_input("æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ (ä¸€è‡´ç®‡æ‰€ã‚’*)")
preset = st.sidebar.selectbox("ãƒ—ãƒªã‚»ãƒƒãƒˆ", list(PRESETS.keys())) if method == "ãƒ—ãƒªã‚»ãƒƒãƒˆ: Email/Phone/CreditCard" else None

# ä¿å­˜å‰ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼é©ç”¨ãƒœã‚¿ãƒ³ï¼ˆä¿å­˜ã¯ã—ãªã„ï¼‰
preview_btn = st.sidebar.button("ğŸ‘€ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ãƒã‚¹ã‚¯é©ç”¨ï¼ˆä¿å­˜ãªã—ï¼‰")

# ãƒˆãƒ¼ã‚¯ãƒ³ãƒãƒƒãƒ— I/O
st.sidebar.subheader("ãƒˆãƒ¼ã‚¯ãƒ³ãƒãƒƒãƒ—ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰")
map_path = st.sidebar.text_input("æ—¢å­˜ãƒãƒƒãƒ—ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹(JSON)")
if st.sidebar.button("ãƒãƒƒãƒ—ã‚’èª­ã¿è¾¼ã‚€", disabled=not map_path):
    try:
        with open(map_path, "r", encoding="utf-8") as f:
            st.session_state.token_map.update(json.load(f))
        st.sidebar.success("ãƒˆãƒ¼ã‚¯ãƒ³ãƒãƒƒãƒ—ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
    except Exception as e:
        st.sidebar.error(f"èª­ã¿è¾¼ã¿å¤±æ•—: {e}")


# -------------------------------
# Preview masked (no save)
# -------------------------------
if 'preview_masked' not in st.session_state:
    st.session_state.preview_masked = None

if 'preview_btn' in locals() and preview_btn:
    st.session_state.preview_masked = _apply_masking(
        df.copy(),
        cols=cols,
        method=method,
        head_n=int(head_n),
        tail_n=int(_tail_n),
        salt=salt,
        regex_pat=regex_pat,
        preset=preset if method == "ãƒ—ãƒªã‚»ãƒƒãƒˆ: Email/Phone/CreditCard" else None,
    )

if st.session_state.preview_masked is not None:
    st.subheader("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆãƒã‚¹ã‚­ãƒ³ã‚°é©ç”¨å¾Œï¼‰")
    st.dataframe(st.session_state.preview_masked.head(n_preview), use_container_width=True)

# -------------------------------
# Apply Masking
# -------------------------------
# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ï¼ˆå¤§å®¹é‡å‘ã‘ï¼‰
st.sidebar.header("ğŸšš ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ï¼ˆå¤§å®¹é‡å‘ã‘ï¼‰")
chunksize = st.sidebar.number_input("chunksize (è¡Œ)", min_value=1000, max_value=2_000_000, value=100_000, step=10_000)
out_dir = st.sidebar.text_input("å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€ï¼ˆæœªæŒ‡å®šãªã‚‰å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã¨åŒã˜ï¼‰", value=os.path.dirname(path))
gzip_save = st.sidebar.checkbox("CSVã¯gzipã§ä¿å­˜ï¼ˆ.csv.gzï¼‰", value=False)
run_stream = st.sidebar.button("â–¶ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§ãƒã‚¹ã‚¯ã—ã¦ä¿å­˜")


# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè¡Œ
if run_stream:
    if not cols:
        st.warning("å¯¾è±¡åˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä¿å­˜ä¸­â€¦"):
            out_path = stream_mask_save(
                path=path,
                header_has_names=header_has_names,
                cols=cols,
                method=method,
                head_n=int(head_n),
                tail_n=int(_tail_n),
                salt=salt,
                regex_pat=regex_pat,
                preset=preset if method == "ãƒ—ãƒªã‚»ãƒƒãƒˆ: Email/Phone/CreditCard" else None,
                chunksize=int(chunksize),
                out_dir=out_dir or None,
                gzip_save=bool(gzip_save),
            )
        st.success(f"âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä¿å­˜ãŒå®Œäº†: {out_path}")
        try:
            size_mb = os.path.getsize(out_path) / (1024*1024)
            st.caption(f"å‡ºåŠ›ã‚µã‚¤ã‚º: {size_mb:.2f} MB")
        except Exception:
            pass
        # å‡ºåŠ›ã®å…ˆé ­ã ã‘ç¢ºèª
        try:
            n_preview_out = st.slider("å‡ºåŠ›ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡Œæ•°", 5, 200, 20, 5, key="outprev")
            st.dataframe(pd.read_csv(out_path, sep=_sep_from_path(out_path), nrows=n_preview_out), use_container_width=True)
        except Exception as e:
            st.info(f"å‡ºåŠ›ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼èª­è¾¼ã‚’ã‚¹ã‚­ãƒƒãƒ—: {e}")


st.subheader("è£œåŠ©ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
st.download_button(
    "ğŸ“¥ ãƒˆãƒ¼ã‚¯ãƒ³ãƒãƒƒãƒ—(JSON)",
    data=json.dumps(st.session_state.token_map, ensure_ascii=False, indent=2),
    file_name="token_map.json",
    mime="application/json",
)

# ç›£æŸ»ç”¨: å®Ÿè¡Œãƒãƒªã‚·ãƒ¼ã®ä¿å­˜
st.subheader("ãƒãƒªã‚·ãƒ¼(å®Ÿè¡Œè¨­å®š)ã®ä¿å­˜")
policy = {
    "columns": cols,
    "method": method,
    "head_n": int(head_n),
    "tail_n": int(_tail_n),
    "salt": salt,
    "regex": regex_pat,
    "preset": preset,
}
st.download_button(
    "ğŸ“„ å®Ÿè¡Œãƒãƒªã‚·ãƒ¼(JSON)ã‚’ä¿å­˜",
    data=json.dumps(policy, ensure_ascii=False, indent=2),
    file_name="mask_policy.json",
    mime="application/json",
)

st.caption("Â© Data Masking App | Streamlit + pandas")
