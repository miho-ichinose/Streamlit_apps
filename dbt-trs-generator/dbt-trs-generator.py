import streamlit as st
import pandas as pd
import re
from io import BytesIO

def convert_excel_type_to_snowflake(excel_type):
    """Excelè¨­è¨ˆæ›¸ã®å‹ã‚’Snowflakeã®å‹ã«å¤‰æ›"""
    type_mapping = {
        'æ–‡å­—åˆ—': 'varchar',
        'VARCHAR': 'varchar',
        'CHAR': 'varchar',
        'TEXT': 'varchar',
        'æ•°å€¤': 'number',
        'NUMBER': 'number',
        'INT': 'number',
        'INTEGER': 'number',
        'DECIMAL': 'number',
        'NUMERIC': 'number',
        'FLOAT': 'float',
        'DOUBLE': 'double',
        'æ—¥ä»˜': 'date',
        'DATE': 'date',
        'æ—¥æ™‚': 'timestamp',
        'DATETIME': 'timestamp',
        'TIMESTAMP': 'timestamp',
        'æ™‚åˆ»': 'time',
        'TIME': 'time',
        'BOOLEAN': 'boolean',
        'BOOL': 'boolean'
    }
    
    if not excel_type:
        return 'varchar(100)'
    
    excel_type_upper = str(excel_type).upper().strip()
    
    # æ‹¬å¼§ä»˜ãã®å‹ã‚’å‡¦ç†ï¼ˆä¾‹ï¼šVARCHAR(100)ï¼‰
    match = re.match(r'([A-Z]+)\((\d+)\)', excel_type_upper)
    if match:
        base_type = match.group(1)
        size = match.group(2)
        if base_type in ['VARCHAR', 'CHAR']:
            return f'varchar({size})'
        elif base_type in ['NUMBER', 'DECIMAL', 'NUMERIC']:
            return f'number({size})'
    
    # æ—¥æœ¬èªã®å‹åã‚’å‡¦ç†
    for key, value in type_mapping.items():
        if key in excel_type_upper or excel_type_upper in key:
            if value == 'varchar' and '(' not in excel_type:
                return 'varchar(100)'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚µã‚¤ã‚º
            return value
    
    return 'varchar(100)'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

def generate_dbt_sql_with_mapping(df, source_schema, source_table, model_name, model_description,
                                 physical_col, type_col, logical_col=None, desc_col=None, 
                                 include_comments=True, selected_rows=None):
    """ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®šã«åŸºã¥ã„ã¦dbt SQLã‚’ç”Ÿæˆ"""
    
    if not physical_col or not type_col:
        st.error("ç‰©ç†åã¨ãƒ‡ãƒ¼ã‚¿å‹ã®ã‚«ãƒ©ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return None, None
    
    # ä½¿ç”¨ã™ã‚‹ã‚«ãƒ©ãƒ ã‚’é¸æŠ
    cols_to_use = [physical_col, type_col]
    if logical_col and logical_col != 'æœªé¸æŠ':
        cols_to_use.append(logical_col)
    if desc_col and desc_col != 'æœªé¸æŠ':
        cols_to_use.append(desc_col)
    
    # é¸æŠã•ã‚ŒãŸè¡Œã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if selected_rows is not None:
        # selected_rowsã®é•·ã•ã‚’dfã«åˆã‚ã›ã‚‹
        selected_mask = selected_rows[:len(df)] + [False] * max(0, len(df) - len(selected_rows))
        selected_mask = selected_mask[:len(df)]
        df_filtered = df[selected_mask].copy()
    else:
        df_filtered = df.copy()
    
    # NaNã‚’é™¤å¤–ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    df_clean = df_filtered[cols_to_use].dropna(subset=[physical_col])
    
    sql = f"""with
    -- å–ã‚Šè¾¼ã¿ã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚ã®æœ€ä½é™ã®å‡¦ç†ã‚’è¡Œã†ã€€â€»''ãŒã‚¨ãƒ©ãƒ¼ã¨ãªã‚‹å‹ã§å–ã‚Šè¾¼ã‚€å ´åˆã¯ã€nullã«å¤‰æ›ã™ã‚‹
    source_data as (
        select"""
    
    # ã‚«ãƒ©ãƒ ã®å‡¦ç†
    columns = []
    col_index = 1  # c1ã‹ã‚‰é–‹å§‹
    for idx, row in df_clean.iterrows():
        col_name = str(row[physical_col]).strip()
        data_type = str(row[type_col]).strip() if pd.notna(row[type_col]) else 'varchar(100)'
        
        if not col_name or col_name == 'nan':
            continue
            
        snowflake_type = convert_excel_type_to_snowflake(data_type)
        
        # æ•°å€¤å‹ã¨æ—¥ä»˜å‹ã®å ´åˆã¯nullifå‡¦ç†ã‚’è¿½åŠ 
        if any(t in snowflake_type.lower() for t in ['number', 'int', 'decimal', 'float', 'double', 'date', 'timestamp']):
            column_def = f"            nullif(value:c{col_index}, '')::{snowflake_type} as {col_name}"
        else:
            column_def = f"            value:c{col_index}::{snowflake_type} as {col_name}"
        
        columns.append(column_def)
        col_index += 1  # æ¬¡ã®ã‚«ãƒ©ãƒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    
    sql += "\n" + ",\n".join(columns)
    sql += f"""
        from {{{{ source("{source_schema}", "{source_table}") }}}}
    )

-- é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚„æ¬ æå€¤ã€æºã‚‰ãã®çŸ¯æ­£ã€ã‚³ãƒ¼ãƒ‰ä½“ç³»ã®çµ±ä¸€ç­‰ã‚’è¡Œã†
select"""
    
    # SELECTå¥ã®ã‚«ãƒ©ãƒ ãƒªã‚¹ãƒˆ
    select_columns = []
    for idx, row in df_clean.iterrows():
        col_name = str(row[physical_col]).strip()
        if col_name and col_name != 'nan':
            # ç‰¹å®šã®ã‚«ãƒ©ãƒ ã«å¯¾ã™ã‚‹å¤‰æ›ãƒ­ã‚¸ãƒƒã‚¯ã®ä¾‹ï¼ˆgenderã®å ´åˆï¼‰
            if 'gender' in col_name.lower() or 'æ€§åˆ¥' in col_name:
                select_columns.append(f"""    case
        when {col_name} is null
        then 0
        when {col_name} = 'ç”·'
        then 1
        when {col_name} = 'å¥³'
        then 2
        else 9
    end as {col_name}""")
            else:
                select_columns.append(f"    {col_name}")
    
    sql += "\n" + ",\n".join(select_columns)
    sql += "\nfrom source_data"
    
    # models.ymlç”¨ã®ã‚¹ã‚­ãƒ¼ãƒå®šç¾©ã‚’ç”Ÿæˆ
    schema_yml = None
    if include_comments and (logical_col and logical_col != 'æœªé¸æŠ' or desc_col and desc_col != 'æœªé¸æŠ'):
        yml_lines = []
        yml_lines.append(f"  - name: {model_name}")
        
        # ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜ã‚’è¿½åŠ 
        if model_description and model_description.strip():
            # æ”¹è¡Œã‚’å‰Šé™¤ã—ã¦1è¡Œã«ã™ã‚‹
            clean_description = model_description.strip().replace('\n', ' ').replace('\r', ' ')
            clean_description = ' '.join(clean_description.split())
            clean_description = clean_description.replace('"', '\\"')
            yml_lines.append(f'    description: "{clean_description}"')
        else:
            yml_lines.append(f'    description: "{model_name}ã®ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©"')
        
        yml_lines.append("    columns:")
        
        for idx, row in df_clean.iterrows():
            col_name = str(row[physical_col]).strip()
            if col_name and col_name != 'nan':
                yml_lines.append(f"      - name: {col_name}")
                
                # èª¬æ˜ã‚’æ§‹ç¯‰
                description_parts = []
                
                # è«–ç†å/é …ç›®åã‚’è¿½åŠ 
                if logical_col and logical_col != 'æœªé¸æŠ' and logical_col in row.index and pd.notna(row[logical_col]):
                    logical_name = str(row[logical_col]).strip()
                    if logical_name and logical_name != 'nan':
                        description_parts.append(logical_name)
                
                # èª¬æ˜ã‚’è¿½åŠ 
                if desc_col and desc_col != 'æœªé¸æŠ' and desc_col in row.index and pd.notna(row[desc_col]):
                    description = str(row[desc_col]).strip()
                    if description and description != 'nan':
                        description_parts.append(description)
                
                if description_parts:
                    # YAMLã®ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆå†…ã§ã®ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†
                    description_text = ': '.join(description_parts) if len(description_parts) > 1 else description_parts[0]
                    # æ”¹è¡Œã‚’å‰Šé™¤
                    description_text = description_text.replace('\n', ' ').replace('\r', ' ')
                    # é€£ç¶šã™ã‚‹ã‚¹ãƒšãƒ¼ã‚¹ã‚’1ã¤ã«
                    description_text = ' '.join(description_text.split())
                    # ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
                    description_text = description_text.replace('"', '\\"')
                    yml_lines.append(f'        description: "{description_text}"')
                else:
                    yml_lines.append(f'        description: "{col_name}"')
                
                # data_testsã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦ã€å¿…è¦ã«å¿œã˜ã¦æ‰‹å‹•ã§è¿½åŠ ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
                yml_lines.append("        # data_tests:")
                yml_lines.append("        #   - not_null")
                if 'id' in col_name.lower() or 'key' in col_name.lower():
                    yml_lines.append("        #   - unique")
        
        if len(yml_lines) > 3:  # ãƒ˜ãƒƒãƒ€ãƒ¼3è¡Œä»¥ä¸Šã®å†…å®¹ãŒã‚ã‚‹å ´åˆ
            schema_yml = '\n'.join(yml_lines)
    
    return sql, schema_yml

def auto_detect_columns(df):
    """ã‚«ãƒ©ãƒ ã‚’è‡ªå‹•æ¤œå‡º"""
    detected = {
        'physical': None,
        'type': None,
        'logical': None,
        'desc': None
    }
    
    for col in df.columns:
        col_str = str(col).strip().lower()
        # ç‰©ç†å
        if any(keyword in col_str for keyword in ['ç‰©ç†å', 'ç‰©ç†', 'ã‚«ãƒ©ãƒ å', 'physical', 'column_name', 'field']):
            detected['physical'] = col
        # ãƒ‡ãƒ¼ã‚¿å‹
        elif any(keyword in col_str for keyword in ['ãƒ‡ãƒ¼ã‚¿å‹', 'ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—', 'å‹', 'type', 'datatype']):
            detected['type'] = col
        # è«–ç†å/é …ç›®å
        elif any(keyword in col_str for keyword in ['è«–ç†å', 'é …ç›®å', 'é …ç›®', 'logical', 'item', 'name']):
            detected['logical'] = col
        # èª¬æ˜
        elif any(keyword in col_str for keyword in ['èª¬æ˜', 'å‚™è€ƒ', 'ã‚³ãƒ¡ãƒ³ãƒˆ', 'description', 'comment', 'remarks', 'note']):
            detected['desc'] = col
    
    return detected

def main():
    st.set_page_config(page_title="dbt SQL Generator", layout="wide")
    
    st.title("ğŸ“Š Excelè¨­è¨ˆæ›¸ã‹ã‚‰dbt SQLç”Ÿæˆãƒ„ãƒ¼ãƒ«")
    st.markdown("Excelã®ãƒ†ãƒ¼ãƒ–ãƒ«è¨­è¨ˆæ›¸ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€Snowflakeå¤–éƒ¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰é€šå¸¸ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã™ã‚‹dbt SQLã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
    
    # å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ãƒã‚§ãƒƒã‚¯
    packages_info = []
    try:
        import openpyxl
        packages_info.append("âœ… openpyxl (for .xlsx files)")
    except ImportError:
        packages_info.append("âŒ openpyxl (for .xlsx files) - `pip install openpyxl`")
    
    try:
        import xlrd
        packages_info.append("âœ… xlrd (for .xls files)")
    except ImportError:
        packages_info.append("âš ï¸ xlrd (for .xls files) - `pip install xlrd` (optional)")
    
    with st.expander("ğŸ“¦ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æƒ…å ±"):
        for info in packages_info:
            st.write(info)
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®š
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        source_schema = st.text_input("Source Schema", value="test", help="dbtã®source schemaã‚’å…¥åŠ›")
        source_table = st.text_input("Source Table", value="customer_master", help="å¤–éƒ¨ãƒ†ãƒ¼ãƒ–ãƒ«åã‚’å…¥åŠ›")
        model_name = st.text_input("Model Name", value="trs_customer_master", help="ç”Ÿæˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«åã‚’å…¥åŠ›")
        model_description = st.text_area(
            "Model Description", 
            value="", 
            help="ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜ï¼ˆmodels.ymlã®descriptionã«ä½¿ç”¨ï¼‰",
            placeholder="ä¾‹: é¡§å®¢ãƒã‚¹ã‚¿"
        )
        
        st.markdown("---")
        st.markdown("### ğŸ“ å¿…è¦ãªExcelã‚«ãƒ©ãƒ ")
        st.markdown("""
        - **ç‰©ç†å** (å¿…é ˆ): ã‚«ãƒ©ãƒ ã®ç‰©ç†å
        - **ãƒ‡ãƒ¼ã‚¿å‹** (å¿…é ˆ): ãƒ‡ãƒ¼ã‚¿å‹
        - **è«–ç†å/é …ç›®å** (ä»»æ„): ã‚³ãƒ¡ãƒ³ãƒˆç”¨
        - **èª¬æ˜/å‚™è€ƒ** (ä»»æ„): ã‚³ãƒ¡ãƒ³ãƒˆç”¨
        """)
    
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
    st.header("ğŸ“ Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_file = st.file_uploader(
        "ãƒ†ãƒ¼ãƒ–ãƒ«è¨­è¨ˆæ›¸ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
        type=['xlsx', 'xls'],
        accept_multiple_files=False,
        help="ç‰©ç†åã¨ãƒ‡ãƒ¼ã‚¿å‹ã®ã‚«ãƒ©ãƒ ã‚’å«ã‚€Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
    )
    
    if uploaded_file is not None:
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’åˆ¤å®šã—ã¦ã‚¨ãƒ³ã‚¸ãƒ³ã‚’é¸æŠ
            file_extension = uploaded_file.name.split('.')[-1].lower()
            
            if file_extension == 'xlsx':
                engine = 'openpyxl'
            elif file_extension == 'xls':
                engine = 'xlrd'
            else:
                st.error("ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚.xlsx ã¾ãŸã¯ .xls ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                st.stop()
            
            # Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
            try:
                excel_file = pd.ExcelFile(uploaded_file, engine=engine)
            except ImportError as e:
                if 'xlrd' in str(e):
                    st.error("âš ï¸ .xlsãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã«ã¯ xlrd ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ï¼š")
                    st.code("pip install xlrd", language="bash")
                    st.stop()
                else:
                    raise e
            
            # ã‚·ãƒ¼ãƒˆé¸æŠ
            sheet_names = excel_file.sheet_names
            selected_sheet = st.selectbox("ã‚·ãƒ¼ãƒˆã‚’é¸æŠ", sheet_names)
            
            # é¸æŠã—ãŸã‚·ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã‚€
            df = pd.read_excel(uploaded_file, sheet_name=selected_sheet, engine=engine)
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            st.subheader("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            st.dataframe(df.head(20), height=300)
            
            # ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®š
            st.subheader("ğŸ”§ ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®š")
            st.info("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç¢ºèªã—ã¦ã€å„ç”¨é€”ã«å¯¾å¿œã™ã‚‹ã‚«ãƒ©ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
            
            # è‡ªå‹•æ¤œå‡º
            detected = auto_detect_columns(df)
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                physical_options = list(df.columns)
                physical_default = physical_options.index(detected['physical']) if detected['physical'] else 0
                physical_col = st.selectbox(
                    "ç‰©ç†åã‚«ãƒ©ãƒ  *å¿…é ˆ", 
                    options=physical_options,
                    index=physical_default,
                    help="ã‚«ãƒ©ãƒ ã®ç‰©ç†åãŒå…¥ã£ã¦ã„ã‚‹åˆ—"
                )
            
            with col2:
                type_options = list(df.columns)
                type_default = type_options.index(detected['type']) if detected['type'] else 0
                type_col = st.selectbox(
                    "ãƒ‡ãƒ¼ã‚¿å‹ã‚«ãƒ©ãƒ  *å¿…é ˆ",
                    options=type_options,
                    index=type_default,
                    help="ãƒ‡ãƒ¼ã‚¿å‹ãŒå…¥ã£ã¦ã„ã‚‹åˆ—"
                )
            
            with col3:
                logical_options = ['æœªé¸æŠ'] + list(df.columns)
                logical_default = logical_options.index(detected['logical']) if detected['logical'] else 0
                logical_col = st.selectbox(
                    "è«–ç†å/é …ç›®åã‚«ãƒ©ãƒ ",
                    options=logical_options,
                    index=logical_default,
                    help="è«–ç†åã‚„é …ç›®åãŒå…¥ã£ã¦ã„ã‚‹åˆ—ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆç”¨ï¼‰"
                )
            
            with col4:
                desc_options = ['æœªé¸æŠ'] + list(df.columns)
                desc_default = desc_options.index(detected['desc']) if detected['desc'] else 0
                desc_col = st.selectbox(
                    "èª¬æ˜/å‚™è€ƒã‚«ãƒ©ãƒ ",
                    options=desc_options,
                    index=desc_default,
                    help="èª¬æ˜ã‚„å‚™è€ƒãŒå…¥ã£ã¦ã„ã‚‹åˆ—ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆç”¨ï¼‰"
                )
            
            # ãƒãƒƒãƒ”ãƒ³ã‚°çµæœã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨è¡Œé¸æŠ
            if st.checkbox("ãƒãƒƒãƒ”ãƒ³ã‚°çµæœã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ»ç·¨é›†", value=True):
                st.subheader("ğŸ“Š ãƒãƒƒãƒ”ãƒ³ã‚°çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                st.info("âœï¸ ç”Ÿæˆå¯¾è±¡ã«å«ã‚ãŸããªã„è¡Œã®ãƒã‚§ãƒƒã‚¯ã‚’å¤–ã—ã¦ãã ã•ã„")
                
                preview_cols = [physical_col, type_col]
                preview_labels = ['ç‰©ç†å', 'ãƒ‡ãƒ¼ã‚¿å‹']
                
                if logical_col != 'æœªé¸æŠ':
                    preview_cols.append(logical_col)
                    preview_labels.append('è«–ç†å/é …ç›®å')
                
                if desc_col != 'æœªé¸æŠ':
                    preview_cols.append(desc_col)
                    preview_labels.append('èª¬æ˜/å‚™è€ƒ')
                
                # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
                preview_df = df[preview_cols].copy()
                preview_df.columns = preview_labels
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§é¸æŠçŠ¶æ…‹ã‚’ç®¡ç†
                if 'selected_rows' not in st.session_state:
                    # åˆæœŸçŠ¶æ…‹ï¼šç‰©ç†åãŒNaNã§ãªã„è¡Œã‚’é¸æŠ
                    st.session_state.selected_rows = preview_df['ç‰©ç†å'].notna().tolist()
                
                # é¸æŠçŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹ãƒœã‚¿ãƒ³
                col1, col2, col3 = st.columns([1, 1, 3])
                with col1:
                    if st.button("âœ… ã™ã¹ã¦é¸æŠ"):
                        st.session_state.selected_rows = [True] * len(preview_df)
                        st.rerun()
                with col2:
                    if st.button("âŒ ã™ã¹ã¦è§£é™¤"):
                        st.session_state.selected_rows = [False] * len(preview_df)
                        st.rerun()
                
                # è¡¨ç¤ºã™ã‚‹è¡Œæ•°ã®é¸æŠ
                display_rows = st.selectbox(
                    "è¡¨ç¤ºè¡Œæ•°",
                    options=[10, 20, 50, 100, "ã™ã¹ã¦"],
                    index=1
                )
                
                if display_rows == "ã™ã¹ã¦":
                    display_limit = len(preview_df)
                else:
                    display_limit = min(display_rows, len(preview_df))
                
                # é¸æŠãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
                display_df = preview_df.head(display_limit).copy()
                
                # é¸æŠçŠ¶æ…‹ã‚’è¡¨ç¤ºç”¨ã«æº–å‚™
                selected_indices = []
                for i in range(display_limit):
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®é•·ã•ã‚’èª¿æ•´
                    if i >= len(st.session_state.selected_rows):
                        st.session_state.selected_rows.append(True)
                
                # ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ‡ã‚£ã‚¿ã‚’ä½¿ç”¨ã—ã¦é¸æŠå¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¡¨ç¤º
                edited_df = pd.DataFrame()
                edited_df['é¸æŠ'] = [st.session_state.selected_rows[i] if i < len(st.session_state.selected_rows) else True for i in range(display_limit)]
                
                # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
                for col in display_df.columns:
                    edited_df[col] = display_df[col].values
                
                # ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ‡ã‚£ã‚¿ã§è¡¨ç¤ºï¼ˆãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ä»˜ãï¼‰
                edited_result = st.data_editor(
                    edited_df,
                    column_config={
                        "é¸æŠ": st.column_config.CheckboxColumn(
                            "é¸æŠ",
                            help="SQLç”Ÿæˆã«å«ã‚ã‚‹è¡Œã‚’é¸æŠ",
                            default=True,
                        )
                    },
                    disabled=[col for col in edited_df.columns if col != 'é¸æŠ'],
                    hide_index=False,
                    use_container_width=True,
                    height=min(600, 35 * display_limit + 35),
                    key="data_editor"
                )
                
                # ç·¨é›†çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«åæ˜ 
                if edited_result is not None:
                    for i in range(len(edited_result)):
                        if i < len(st.session_state.selected_rows):
                            st.session_state.selected_rows[i] = edited_result['é¸æŠ'].iloc[i]
                
                # é¸æŠã•ã‚ŒãŸè¡Œæ•°ã‚’è¡¨ç¤º
                selected_count = sum(edited_result['é¸æŠ']) if edited_result is not None else 0
                st.success(f"ğŸ“Š {selected_count} / {display_limit} è¡ŒãŒé¸æŠã•ã‚Œã¦ã„ã¾ã™")
                
                if display_limit < len(preview_df):
                    st.warning(f"âš ï¸ å…¨ {len(preview_df)} è¡Œä¸­ {display_limit} è¡Œã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™")
            
            st.markdown("---")
            
            # SQLç”Ÿæˆ
            st.subheader("ğŸ”„ SQLç”Ÿæˆ")
            
            # ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
            include_comments = st.checkbox(
                "ğŸ“ models.ymlå®šç¾©ã‚‚ç”Ÿæˆ", 
                value=True,
                disabled=(logical_col == 'æœªé¸æŠ' and desc_col == 'æœªé¸æŠ'),
                help="é …ç›®åã¨èª¬æ˜ã‹ã‚‰dbtã®models.ymlå®šç¾©ã‚’ç”Ÿæˆã—ã¾ã™"
            )
            
            if st.button("ğŸš€ SQLç”Ÿæˆ", type="primary", use_container_width=True):
                # é¸æŠã•ã‚ŒãŸè¡Œã‚’å–å¾—
                selected_rows = st.session_state.get('selected_rows', None)
                
                sql, schema_yml = generate_dbt_sql_with_mapping(
                    df, source_schema, source_table, model_name, model_description,
                    physical_col, type_col, 
                    logical_col if logical_col != 'æœªé¸æŠ' else None,
                    desc_col if desc_col != 'æœªé¸æŠ' else None,
                    include_comments,
                    selected_rows
                )
                
                if sql:
                    # ãƒ¡ã‚¤ãƒ³SQLã‚’è¡¨ç¤º
                    st.subheader("ğŸ“„ dbt Model SQL")
                    st.code(sql, language='sql', line_numbers=True)
                    
                    # models.ymlã‚’è¡¨ç¤º
                    if schema_yml and include_comments:
                        st.subheader("ğŸ“ models.ymlå®šç¾©")
                        st.info("ã“ã®YAMLå®šç¾©ã‚’models.ymlãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
                        st.code(schema_yml, language='yaml', line_numbers=True)
                    
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                    col1, col2 = st.columns(2)
                    with col1:
                        st.download_button(
                            label="ğŸ“¥ Model SQLã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=sql,
                            file_name=f"{model_name}.sql",
                            mime="text/plain",
                            use_container_width=True
                        )
                    
                    with col2:
                        if schema_yml and include_comments:
                            st.download_button(
                                label="ğŸ“¥ models.ymlå®šç¾©ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=schema_yml,
                                file_name=f"{model_name}_schema.yml",
                                mime="text/yaml",
                                use_container_width=True
                            )
                    
                    # çµ±è¨ˆæƒ…å ±
                    st.subheader("ğŸ“ˆ ç”Ÿæˆæƒ…å ±")
                    col_count = len([line for line in sql.split('\n') if 'as ' in line and 'select' not in line.lower()])
                    metrics_col1, metrics_col2 = st.columns(2)
                    with metrics_col1:
                        st.metric("ç”Ÿæˆã•ã‚ŒãŸã‚«ãƒ©ãƒ æ•°", col_count)
                    with metrics_col2:
                        if schema_yml:
                            yml_col_count = len([line for line in schema_yml.split('\n') if '- name:' in line and 'columns:' not in line])
                            st.metric("ã‚¹ã‚­ãƒ¼ãƒå®šç¾©ã‚«ãƒ©ãƒ æ•°", yml_col_count)
            
        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
    else:
        st.info("ğŸ‘† Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    
    # ä½¿ã„æ–¹
    with st.expander("ğŸ“– ä½¿ã„æ–¹"):
        st.markdown("""
        ### ä½¿ç”¨æ–¹æ³•
        1. **Excelãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™**: ãƒ†ãƒ¼ãƒ–ãƒ«è¨­è¨ˆæ›¸ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨æ„
        2. **ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        3. **ã‚·ãƒ¼ãƒˆé¸æŠ**: å¯¾è±¡ã®ã‚·ãƒ¼ãƒˆã‚’é¸æŠ
        4. **ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°**: å„ç”¨é€”ã«å¯¾å¿œã™ã‚‹ã‚«ãƒ©ãƒ ã‚’é¸æŠ
           - ç‰©ç†åï¼ˆå¿…é ˆï¼‰: ã‚«ãƒ©ãƒ ã®ç‰©ç†å
           - ãƒ‡ãƒ¼ã‚¿å‹ï¼ˆå¿…é ˆï¼‰: Snowflakeã®ãƒ‡ãƒ¼ã‚¿å‹
           - è«–ç†å/é …ç›®åï¼ˆä»»æ„ï¼‰: ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆç”¨
           - èª¬æ˜/å‚™è€ƒï¼ˆä»»æ„ï¼‰: ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆç”¨
        5. **è¨­å®šç¢ºèª**: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§schema, tableåã‚’è¨­å®š
        6. **SQLç”Ÿæˆ**: ã€ŒSQLç”Ÿæˆã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
        7. **ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**: ç”Ÿæˆã•ã‚ŒãŸSQLã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        
        ### ã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿å‹
        - VARCHAR(n), CHAR(n) â†’ varchar(n)
        - NUMBER, INT, DECIMAL â†’ number
        - DATE â†’ date
        - TIMESTAMP, DATETIME â†’ timestamp
        - FLOAT â†’ float
        - BOOLEAN â†’ boolean
        
        ### ç‰¹æ®Šå‡¦ç†
        - æ•°å€¤å‹ãƒ»æ—¥ä»˜å‹: `nullif(value:column, '')` ã§ç©ºæ–‡å­—ã‚’NULLã«å¤‰æ›
        - gender/æ€§åˆ¥ã‚«ãƒ©ãƒ : è‡ªå‹•çš„ã«ã‚³ãƒ¼ãƒ‰å¤‰æ›ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ 
        
        ### dbtã§ã®æ´»ç”¨
        ç”Ÿæˆã•ã‚ŒãŸmodels.ymlå®šç¾©ã¯ã€æ—¢å­˜ã®models.ymlãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½åŠ ã—ã¦ãã ã•ã„ï¼š
        
        ```yaml
        version: 2
        
        models:
          - name: stg_customer
            description: "stg_customerã®ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©"
            columns:
              - name: serial_number
                description: "ã‚·ãƒªã‚¢ãƒ«ç•ªå·: é¡§å®¢ã‚’ä¸€æ„ã«è­˜åˆ¥ã™ã‚‹ç•ªå·"
                # data_tests:
                #   - not_null
                #   - unique
              - name: full_name
                description: "æ°å: é¡§å®¢ã®æ°å"
                # data_tests:
                #   - not_null
        ```
        
        **data_testsã«ã¤ã„ã¦**:
        - data_testsã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦ç”Ÿæˆã•ã‚Œã¾ã™
        - å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ“ã‚¸ãƒã‚¹ãƒ«ãƒ¼ãƒ«ã«å¿œã˜ã¦ã€å¿…è¦ãªãƒ†ã‚¹ãƒˆã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å¤–ã—ã¦ãã ã•ã„
        - IDã‚„KEYã‚’å«ã‚€ã‚«ãƒ©ãƒ ã«ã¯`unique`ãƒ†ã‚¹ãƒˆã®å€™è£œã‚‚å«ã¾ã‚Œã¾ã™
        """)

if __name__ == "__main__":
    main()